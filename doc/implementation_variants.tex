We consider two implementation variants in this work. The first variant employs a straightforward distributed-memory parallelization based on the Message Passing Interface (MPI). In this baseline implementation, the computational domain is decomposed across MPI ranks, with each process responsible for a subset of the global problem of size \(N\). Collective communication routines are used to exchange boundary data and to perform global reductions when required.

This MPI-based approach provides acceptable performance for moderate problem sizes; however, as \(N\) increases, scalability becomes limited by communication overhead and synchronization costs. In particular, the frequency of collective operations and the volume of inter-process communication lead to reduced parallel efficiency at larger scales.

To overcome these limitations, a second implementation optimized for large problem sizes was developed. This optimized variant builds upon the original MPI framework but introduces several improvements targeting large-\(N\) scalability. These include reducing the number of global synchronization points, overlapping communication with computation, and reorganizing data structures to improve memory locality and cache utilization. Furthermore, communication patterns are redesigned to minimize message counts and to favor contiguous data transfers.

The optimized implementation significantly improves strong and weak scaling behavior for large \(N\), enabling efficient execution on a higher number of processes. Performance results presented in Section~\ref{sec:results} demonstrate that this approach achieves better scalability and higher sustained throughput compared to the baseline MPI implementation, particularly for large-scale configurations.
